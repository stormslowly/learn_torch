{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 数据来源\n",
    "ref <https://github.com/fchollet/keras/blob/master/keras/datasets/mnist.py>\n",
    "```\n",
    "    f = np.load(path)\n",
    "    x_train = f['x_train']\n",
    "    y_train = f['y_train']\n",
    "    x_test = f['x_test']\n",
    "    y_test = f['y_test']\n",
    "    f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f = np.load('./mnist.npz')\n",
    "x_train = f['x_train']\n",
    "y_train = f['y_train']\n",
    "x_test = f['x_test']\n",
    "y_test = f['y_test']\n",
    "\n",
    "print(x_train[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 (28, 28)\n",
      "784\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngAahEAAkCgFAohAAJAoBQPo/4Tui0AbQI88AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cae1198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "SAMPLE_INDEX= 42\n",
    "\n",
    "sample_matrix = x_train[SAMPLE_INDEX]\n",
    "\n",
    "plot.matshow(x_train[SAMPLE_INDEX])\n",
    "print( y_train[SAMPLE_INDEX], sample_matrix.shape)\n",
    "\n",
    "print( len( sample_matrix.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.4485\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "5 Variable containing:\n",
      "    0     1     0     0     0     0     0     0     0     0\n",
      "[torch.ByteTensor of size 1x10]\n",
      "\n",
      "0 Variable containing:\n",
      "    1     0     0     0     0     0     0     0     0     0\n",
      "[torch.ByteTensor of size 1x10]\n",
      "\n",
      "4 Variable containing:\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "[torch.ByteTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the simpleset network\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "row = sample_matrix[0]\n",
    "\n",
    "tx  = torch.Tensor([[1 if x>0 else 0 for x in sample_matrix.flatten()]])\n",
    "\n",
    "def mnist2Var(sample):\n",
    "    return Variable(torch.Tensor([[1 if x>0 else 0 for x in sample.flatten()]]),requires_grad=False)\n",
    "\n",
    "def mnist2List(sample):\n",
    "    return [1 if x>0 else 0 for x in sample.flatten()]\n",
    "\n",
    "\n",
    "def toExpectVar(num):\n",
    "    v = np.zeros([1,10])\n",
    "    v[0][num]= 1\n",
    "    return v\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.4500\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "5 Variable containing:\n",
      "    0     0     0     1     0     1     0     0     0     0\n",
      "[torch.ByteTensor of size 1x10]\n",
      "\n",
      "0 Variable containing:\n",
      "    1     0     0     0     0     0     0     0     0     0\n",
      "[torch.ByteTensor of size 1x10]\n",
      "\n",
      "4 Variable containing:\n",
      "    0     0     0     0     1     0     0     0     0     0\n",
      "[torch.ByteTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = torch.nn.functional.softmax\n",
    "relu = torch.nn.functional.relu\n",
    "\n",
    "w = Variable(torch.ones(784,10),requires_grad=True)   #784 x 10\n",
    "b = Variable(torch.ones(1,10), requires_grad=True)\n",
    "\n",
    "\n",
    "def h(x):\n",
    "    return softmax( relu(x.mm(w) + b ))\n",
    "\n",
    "ctriter = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "batchSize=1\n",
    "\n",
    "for r in range(1):\n",
    "    for i in range(10):\n",
    "        subX =[ mnist2List(data) for data in x_train[i*batchSize:(1+i)*batchSize]]\n",
    "        \n",
    "        subX = Variable(torch.Tensor(subX),requires_grad=False)\n",
    "        subExpectY  = y_train[i*batchSize:(1+i)*batchSize]\n",
    "        \n",
    "\n",
    "        prey = h(subX)\n",
    "        y = Variable(torch.zeros(1,10))\n",
    "        subExpectY = [ toExpectVar(y) for y in subExpectY]\n",
    "        subExpectY = Variable(torch.Tensor(subExpectY),requires_grad=True)\n",
    "        loss = 0.5*(prey - subExpectY).pow(2).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        w.data -= 0.000001*w.grad.data\n",
    "        b.data -= 0.000001*b.grad.data\n",
    "\n",
    "       \n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "\n",
    "\n",
    "print( loss)\n",
    "\n",
    "for i in range(3):\n",
    "    index = i\n",
    "    result =h(mnist2Var(x_train[index]))\n",
    "    print (y_train[index], result==torch.max(result.data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
